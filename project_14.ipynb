{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb6a041e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nodes:               6426\n",
      "Total edges:               167219\n",
      "Avg degree centrality:     0.008100\n",
      "Standard dev centrality:   0.017689\n",
      "Min centrality:            0.000156\n",
      "Max centrality:            0.296965\n",
      "\n",
      "Node with max centrality:  CAPTAIN AMERICA (0.296965)\n",
      "Node with min centrality:  AZRAEL (0.000156)\n",
      "Top 5 nodes closest to avg centrality:\n",
      "  JONES, TAMMY ANNE (0.008093)\n",
      "  JONES, LORRAINE LORR (0.008093)\n",
      "  JONES, DANIEL DANNY (0.008093)\n",
      "  NEVILLE, KATE (0.008093)\n",
      "  PEARSON, MARCY (0.008093)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "edges = pd.read_csv('hero-network.csv')  \n",
    "\n",
    "G = nx.from_pandas_edgelist(\n",
    "    edges,\n",
    "    source='hero1',\n",
    "    target='hero2',\n",
    "    create_using=nx.Graph()\n",
    ")\n",
    "\n",
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()\n",
    "\n",
    "deg_cent = nx.degree_centrality(G)\n",
    "cent_values = np.array(list(deg_cent.values()))\n",
    "\n",
    "avg_cent = cent_values.mean()\n",
    "std_cent = cent_values.std(ddof=0)\n",
    "min_cent = cent_values.min()\n",
    "max_cent = cent_values.max()\n",
    "\n",
    "node_max = max(deg_cent, key=deg_cent.get)\n",
    "node_min = min(deg_cent, key=deg_cent.get)\n",
    "nodes_near_avg = sorted(\n",
    "    deg_cent,\n",
    "    key=lambda n: abs(deg_cent[n] - avg_cent)\n",
    ")[:5]\n",
    "\n",
    "print(f\"Total nodes:               {num_nodes}\")\n",
    "print(f\"Total edges:               {num_edges}\")\n",
    "print(f\"Avg degree centrality:     {avg_cent:.6f}\")\n",
    "print(f\"Standard dev centrality:   {std_cent:.6f}\")\n",
    "print(f\"Min centrality:            {min_cent:.6f}\")\n",
    "print(f\"Max centrality:            {max_cent:.6f}\")\n",
    "print()\n",
    "print(f\"Node with max centrality:  {node_max} ({deg_cent[node_max]:.6f})\")\n",
    "print(f\"Node with min centrality:  {node_min} ({deg_cent[node_min]:.6f})\")\n",
    "print(\"Top 5 nodes closest to avg centrality:\")\n",
    "for n in nodes_near_avg:\n",
    "    print(f\"  {n} ({deg_cent[n]:.6f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fe898e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        n_nodes  avg_distance  var_distance\n",
      "degree                                     \n",
      "1            53      3.270376      0.264671\n",
      "2            86      3.260739      0.260606\n",
      "3           104      3.226475      0.264056\n",
      "4           150      3.104609      0.222704\n",
      "5           182      3.139336      0.249968\n",
      "...         ...           ...           ...\n",
      "497           2      1.000000      0.000000\n",
      "526           2      1.000000      0.000000\n",
      "539           2      1.000000      0.000000\n",
      "585           2      1.000000      0.000000\n",
      "922           2      1.000000      0.000000\n",
      "\n",
      "[242 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "deg_dict = dict(G.degree())\n",
    "\n",
    "degree_to_nodes = {}\n",
    "for node, deg in deg_dict.items():\n",
    "    degree_to_nodes.setdefault(deg, []).append(node)\n",
    "\n",
    "results = []\n",
    "for k, nodes in sorted(degree_to_nodes.items()):\n",
    "    if len(nodes) < 2:\n",
    "        # skip degrees with fewer than 2 nodes\n",
    "        continue\n",
    "\n",
    "    dists = []\n",
    "    for u, v in combinations(nodes, 2):\n",
    "        try:\n",
    "            d = nx.shortest_path_length(G, source=u, target=v)\n",
    "            dists.append(d)\n",
    "        except nx.NetworkXNoPath:\n",
    "            # if no path exists, you can choose to count it as np.nan,\n",
    "            # or skip it; here we skip\n",
    "            pass\n",
    "\n",
    "    if len(dists) > 0:\n",
    "        avg_dist = np.mean(dists)\n",
    "        var_dist = np.var(dists, ddof=0)  # population variance\n",
    "    else:\n",
    "        avg_dist = np.nan\n",
    "        var_dist = np.nan\n",
    "\n",
    "    results.append({\n",
    "        'degree': k,\n",
    "        'n_nodes': len(nodes),\n",
    "        'avg_distance': avg_dist,\n",
    "        'var_distance': var_dist\n",
    "    })\n",
    "\n",
    "# 6. Summarize in a pandas DataFrame and print\n",
    "df_summary = pd.DataFrame(results).set_index('degree')\n",
    "print(df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97db5d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        n_nodes   avg_sim   std_sim\n",
      "degree                             \n",
      "1            53  0.023948  0.152886\n",
      "2            86  0.014227  0.087931\n",
      "3           104  0.011265  0.073284\n",
      "4           150  0.017651  0.085114\n",
      "5           182  0.016356  0.087057\n",
      "...         ...       ...       ...\n",
      "497           2  0.382294  0.000000\n",
      "526           2  0.359316  0.000000\n",
      "539           2  0.278293  0.000000\n",
      "585           2  0.213675  0.000000\n",
      "922           2  0.427332  0.000000\n",
      "\n",
      "[242 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for k, nodes in sorted(degree_to_nodes.items()):\n",
    "    if len(nodes) < 2:\n",
    "        continue  # skip degrees with fewer than 2 nodes\n",
    "\n",
    "    sims = []\n",
    "    for u, v in combinations(nodes, 2):\n",
    "        nbrs_u = set(G.neighbors(u))\n",
    "        nbrs_v = set(G.neighbors(v))\n",
    "        # if degree k > 0, compute cosine similarity; otherwise skip\n",
    "        if k > 0:\n",
    "            sim = len(nbrs_u & nbrs_v) / np.sqrt(k * k)\n",
    "            sims.append(sim)\n",
    "\n",
    "    if sims:\n",
    "        avg_sim  = np.mean(sims)\n",
    "        std_sim  = np.std(sims, ddof=0)   # population standard deviation\n",
    "    else:\n",
    "        avg_sim, std_sim = np.nan, np.nan\n",
    "\n",
    "    results.append({\n",
    "        'degree':    k,\n",
    "        'n_nodes':   len(nodes),\n",
    "        'avg_sim':   avg_sim,\n",
    "        'std_sim':   std_sim\n",
    "    })\n",
    "\n",
    "# 5. Summarize in a DataFrame and print\n",
    "df_struct_eq = pd.DataFrame(results).set_index('degree')\n",
    "print(df_struct_eq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
